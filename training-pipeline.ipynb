{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages that are useful\n",
    "import hopsworks\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1110 entries, 0 to 1137\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   id                1110 non-null   object \n",
      " 1   code              1110 non-null   int64  \n",
      " 2   description       1110 non-null   object \n",
      " 3   endTime           1110 non-null   object \n",
      " 4   hour              1110 non-null   int64  \n",
      " 5   iconCategory      1110 non-null   int64  \n",
      " 6   latitude          1110 non-null   float64\n",
      " 7   longitude         1110 non-null   float64\n",
      " 8   magnitudeOfDelay  1110 non-null   int64  \n",
      " 9   month             1110 non-null   int64  \n",
      " 10  startTime         1110 non-null   object \n",
      " 11  type              1110 non-null   object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 112.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Read the data from incidents.csv and print the number of incidents per day\n",
    "df = pd.read_csv(\"incidents.csv\")\n",
    "\n",
    "# Drop the features with too many missing values\n",
    "df = df.drop(columns=[\"apparent_temperature\", \"date\", \"dew_point_2m\", \"is_day\", \"precipitation\", \"et0_fao_evapotranspiration\", \"rain\", \"snow_depth\", \"snowfall\", \"soil_temperature_0_to_7cm\", \"weather_code\", \"wind_speed_10m\", \"surface_pressure\", \"sunshine_duration\", \"relative_humidity_2m\", \"temperature_2m\", \"vapour_pressure_deficit\", \"Unnamed: 0.4\", \"Unnamed: 0.3\", \"Unnamed: 0.2\", \"Unnamed: 0.1\", \"Unnamed: 0\"])\n",
    "\n",
    "# Remove rows with no end time\n",
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the labels by getting the difference between start and end time\n",
    "df['duration'] = pd.to_datetime(df[\"endTime\"]) - pd.to_datetime(df[\"startTime\"])\n",
    "\n",
    "# Remove the start time and end time columns\n",
    "df = df.drop([\"startTime\", \"endTime\", \"type\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>description</th>\n",
       "      <th>hour</th>\n",
       "      <th>iconCategory</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>magnitudeOfDelay</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1110.000000</td>\n",
       "      <td>1110.000000</td>\n",
       "      <td>1110.000000</td>\n",
       "      <td>1110.000000</td>\n",
       "      <td>1110.000000</td>\n",
       "      <td>1110.000000</td>\n",
       "      <td>1110.000000</td>\n",
       "      <td>1110.000000</td>\n",
       "      <td>1110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>197.289189</td>\n",
       "      <td>8.600901</td>\n",
       "      <td>13.756757</td>\n",
       "      <td>6.096396</td>\n",
       "      <td>59.319866</td>\n",
       "      <td>18.057985</td>\n",
       "      <td>1.850450</td>\n",
       "      <td>11.905405</td>\n",
       "      <td>11 days 14:13:02.545045045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>255.011017</td>\n",
       "      <td>3.059111</td>\n",
       "      <td>5.095333</td>\n",
       "      <td>1.348507</td>\n",
       "      <td>0.036881</td>\n",
       "      <td>0.041765</td>\n",
       "      <td>1.068094</td>\n",
       "      <td>0.808581</td>\n",
       "      <td>114 days 00:42:07.801110800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.198197</td>\n",
       "      <td>17.870475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0 days 00:08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>59.296146</td>\n",
       "      <td>18.025949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0 days 01:05:06.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>108.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>59.320930</td>\n",
       "      <td>18.057546</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0 days 01:08:36.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>115.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>59.345150</td>\n",
       "      <td>18.088704</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0 days 01:22:46.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1472.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>59.446342</td>\n",
       "      <td>18.287681</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1617 days 01:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              code  description         hour  iconCategory     latitude  \\\n",
       "count  1110.000000  1110.000000  1110.000000   1110.000000  1110.000000   \n",
       "mean    197.289189     8.600901    13.756757      6.096396    59.319866   \n",
       "std     255.011017     3.059111     5.095333      1.348507     0.036881   \n",
       "min     101.000000     0.000000     0.000000      1.000000    59.198197   \n",
       "25%     101.000000     7.000000    11.000000      6.000000    59.296146   \n",
       "50%     108.000000    10.000000    14.000000      6.000000    59.320930   \n",
       "75%     115.000000    11.000000    17.000000      6.000000    59.345150   \n",
       "max    1472.000000    11.000000    23.000000     14.000000    59.446342   \n",
       "\n",
       "         longitude  magnitudeOfDelay        month                     duration  \n",
       "count  1110.000000       1110.000000  1110.000000                         1110  \n",
       "mean     18.057985          1.850450    11.905405   11 days 14:13:02.545045045  \n",
       "std       0.041765          1.068094     0.808581  114 days 00:42:07.801110800  \n",
       "min      17.870475          0.000000     1.000000              0 days 00:08:00  \n",
       "25%      18.025949          1.000000    12.000000       0 days 01:05:06.250000  \n",
       "50%      18.057546          2.000000    12.000000       0 days 01:08:36.500000  \n",
       "75%      18.088704          3.000000    12.000000       0 days 01:22:46.750000  \n",
       "max      18.287681          4.000000    12.000000           1617 days 01:00:00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the label encoder to encode the description feature\n",
    "le = LabelEncoder()\n",
    "le.fit(df[\"description\"])\n",
    "df[\"description\"] = le.transform(df[\"description\"])\n",
    "\n",
    "# Remove the id column\n",
    "df = df.drop(\"id\", axis=1)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the duration to seconds\n",
    "df[\"duration\"] = df[\"duration\"].dt.total_seconds()\n",
    "\n",
    "# Use a log scale for the duration\n",
    "df[\"duration\"] = df[\"duration\"].astype(\"int64\")\n",
    "df[\"duration\"] = np.log(df[\"duration\"])\n",
    "y = df[\"duration\"]\n",
    "\n",
    "# create the x values without dropping the duration in the df\n",
    "X = df.drop(\"duration\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7610436329637739"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "\n",
    "# train and test the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try a NN model \n",
    "# from sklearn.neural_network import MLPRegressor\n",
    "# mlp = MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000, alpha=0.0001,\n",
    "#                      solver='sgd', verbose=10,  random_state=21,tol=0.000000001)\n",
    "# mlp.fit(X_train, y_train)\n",
    "# mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/281749\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "# Log in to Hopsworks\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/281749/fs/281668/fg/376147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 1110/1110 | Elapsed Time: 00:05 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: incidents_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/281749/jobs/named/incidents_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x18623a802b0>, None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the columns lowercase \n",
    "df.columns = df.columns.str.lower()\n",
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "\n",
    "# Create the feature group\n",
    "fg = fs.create_feature_group(\"incidents\", version=1, description=\"Incidents in the city of Stockholm\", \n",
    "                             primary_key=df.columns.tolist(),)\n",
    "fg.insert(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid split input. You should specify either (`validation_size` and `test_size`) or ((`train_end` or `validation_start`) and (`validation_end` or `test_start`)).`validation_size`, `test_size` and sum of `validationSize` and `testSize` should be between 0 and 1 if specified.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m fg\u001b[38;5;241m.\u001b[39mselect_all()\n\u001b[0;32m      2\u001b[0m feature_view \u001b[38;5;241m=\u001b[39m fs\u001b[38;5;241m.\u001b[39mget_or_create_feature_view(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincidents_view\u001b[39m\u001b[38;5;124m\"\u001b[39m, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncidents in the city of Stockholm\u001b[39m\u001b[38;5;124m\"\u001b[39m,  labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m\"\u001b[39m], query\u001b[38;5;241m=\u001b[39mquery)\n\u001b[1;32m----> 3\u001b[0m X_train, X_val, y_val, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_view\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_validation_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\hsfs\\feature_view.py:1970\u001b[0m, in \u001b[0;36mFeatureView.train_validation_test_split\u001b[1;34m(self, validation_size, test_size, train_start, train_end, validation_start, validation_end, test_start, test_end, description, extra_filter, statistics_config, read_options, spine)\u001b[0m\n\u001b[0;32m   1832\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_validation_test_split\u001b[39m(\n\u001b[0;32m   1833\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1834\u001b[0m     validation_size: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1855\u001b[0m     ] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1856\u001b[0m ):\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1858\u001b[0m \u001b[38;5;124;03m    Create the metadata for a training dataset and get the corresponding training data from the offline feature store.\u001b[39;00m\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;124;03m    This returns the training data in memory and does not materialise data in storage.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1967\u001b[0m \u001b[38;5;124;03m            Tuple of dataframe of features and labels\u001b[39;00m\n\u001b[0;32m   1968\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1970\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_train_validation_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_end\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_end\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1977\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1978\u001b[0m     td \u001b[38;5;241m=\u001b[39m training_dataset\u001b[38;5;241m.\u001b[39mTrainingDataset(\n\u001b[0;32m   1979\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m   1980\u001b[0m         version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1998\u001b[0m         extra_filter\u001b[38;5;241m=\u001b[39mextra_filter,\n\u001b[0;32m   1999\u001b[0m     )\n\u001b[0;32m   2000\u001b[0m     td, df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_view_engine\u001b[38;5;241m.\u001b[39mget_training_data(\n\u001b[0;32m   2001\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2002\u001b[0m         read_options,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2009\u001b[0m         spine\u001b[38;5;241m=\u001b[39mspine,\n\u001b[0;32m   2010\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\hsfs\\feature_view.py:2032\u001b[0m, in \u001b[0;36mFeatureView._validate_train_validation_test_split\u001b[1;34m(validation_size, test_size, train_end, validation_start, validation_end, test_start)\u001b[0m\n\u001b[0;32m   2017\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m   2018\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_train_validation_test_split\u001b[39m(\n\u001b[0;32m   2019\u001b[0m     validation_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2024\u001b[0m     test_start,\n\u001b[0;32m   2025\u001b[0m ):\n\u001b[0;32m   2026\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m   2027\u001b[0m         (validation_size \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m validation_size \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   2028\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (test_size \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m test_size \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   2029\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (validation_size \u001b[38;5;241m+\u001b[39m test_size \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   2030\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m ((train_end \u001b[38;5;129;01mor\u001b[39;00m validation_start) \u001b[38;5;129;01mand\u001b[39;00m (validation_end \u001b[38;5;129;01mor\u001b[39;00m test_start))\n\u001b[0;32m   2031\u001b[0m     ):\n\u001b[1;32m-> 2032\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2033\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid split input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2034\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m You should specify either (`validation_size` and `test_size`) or ((`train_end` or `validation_start`) and (`validation_end` or `test_start`)).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2035\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_size`, `test_size` and sum of `validationSize` and `testSize` should be between 0 and 1 if specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2036\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid split input. You should specify either (`validation_size` and `test_size`) or ((`train_end` or `validation_start`) and (`validation_end` or `test_start`)).`validation_size`, `test_size` and sum of `validationSize` and `testSize` should be between 0 and 1 if specified."
     ]
    }
   ],
   "source": [
    "query = fg.select_all()\n",
    "feature_view = fs.get_or_create_feature_view(\"incidents_view\", version=1, description=\"Incidents in the city of Stockholm\",  labels=[\"duration\"], query=query)\n",
    "X_train, X_val, y_val, y_test = feature_view.train_validation_test_split(test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n"
     ]
    }
   ],
   "source": [
    "# Train a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "\n",
    "# train and test the model\n",
    "lr.fit(X_train, y_train)\n",
    "metric = lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model export complete: 100%|██████████| 6/6 [00:09<00:00,  1.57s/it]                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/281749/models/stockholm_incidents_model/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(name: 'stockholm_incidents_model', version: 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will now upload the linear regression model to the registry\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# The directory will be wine_model\n",
    "model_dir=\"stockholm_incidents_model\"\n",
    "if os.path.isdir(model_dir) == False:\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(lr, model_dir + \"/stckhlm_inc_model.pkl\")\n",
    "\n",
    "# Specify the input and output\n",
    "input_schema = Schema(X_train)\n",
    "output_schema = Schema(y_train)\n",
    "model_schema = ModelSchema(input_schema, output_schema)\n",
    "\n",
    "# Create an entry\n",
    "wine_model = mr.python.create_model(\n",
    "    name=\"stockholm_incidents_model\", \n",
    "    metrics={\"MSE\" : metric},\n",
    "    model_schema=model_schema,\n",
    "    description=\"Stockholm Incident duration Predictor\"\n",
    ")\n",
    "\n",
    "# Upload the model to the model registry, including all files in 'model_dir'\n",
    "wine_model.save(model_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
