{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6166152922497015"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "\n",
    "# train and test the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3225987489290634\n",
      "0.5240861558855514\n",
      "0.23214047765247603\n",
      "0.6453002910148729\n",
      "-0.9367850107783138\n",
      "0.5768242110534658\n",
      "0.8118657056470845\n"
     ]
    }
   ],
   "source": [
    "# Import the neural network model\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp = MLPRegressor()\n",
    "\n",
    "# train and test the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "mlp.fit(X_train, y_train)\n",
    "mlp.score(X_test, y_test)\n",
    "print(mlp.score(X_test, y_test))\n",
    "\n",
    "# Import the random forest model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# train and test the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)\n",
    "print(rf.score(X_test, y_test))\n",
    "\n",
    "# Import the gradient boosting model\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gb = GradientBoostingRegressor()\n",
    "\n",
    "# train and test the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "gb.fit(X_train, y_train)\n",
    "gb.score(X_test, y_test)\n",
    "print(gb.score(X_test, y_test))\n",
    "\n",
    "# Import the decision tree model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor()\n",
    "\n",
    "# train and test the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "dt.fit(X_train, y_train)\n",
    "dt.score(X_test, y_test)\n",
    "print(dt.score(X_test, y_test))\n",
    "\n",
    "# Import the KNN model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# train and test the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_test, y_test)\n",
    "print(knn.score(X_test, y_test))\n",
    "\n",
    "# Import the SVM model\n",
    "from sklearn.svm import SVR\n",
    "svr = SVR()\n",
    "\n",
    "# train and test the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "svr.fit(X_train, y_train)\n",
    "svr.score(X_test, y_test)\n",
    "print(svr.score(X_test, y_test))\n",
    "\n",
    "# Import the XGBoost model\n",
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "# train and test the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb.score(X_test, y_test)\n",
    "print(xgb.score(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.2.0-py3-none-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\ merlijn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from lightgbm) (1.26.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\ merlijn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from lightgbm) (1.11.4)\n",
      "Downloading lightgbm-4.2.0-py3-none-win_amd64.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.2/1.3 MB 5.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.7/1.3 MB 8.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.2/1.3 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 9.4 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/194708\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "# Log in to Hopsworks\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 1000/1000 | Elapsed Time: 00:05 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: incidents_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/194708/jobs/named/incidents_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x22dfde27ad0>, None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the columns lowercase \n",
    "df.columns = df.columns.str.lower()\n",
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "\n",
    "# Create the feature group\n",
    "# fg = fs.create_feature_group(\"incidents\", version=1, description=\"Incidents in the city of Stockholm\", \n",
    "#                              primary_key=df.columns.tolist(),)\n",
    "fg = fs.get_feature_group(\"incidents\", version=1)\n",
    "fg.insert(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (1.39s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: Incremented version to `3`.\n"
     ]
    }
   ],
   "source": [
    "query = fg.select_all()\n",
    "feature_view = fs.get_or_create_feature_view(\"incidents_view\", version=1, description=\"Incidents in the city of Stockholm\",  labels=[\"duration\"], query=query)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = feature_view.train_validation_test_split(0.1, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "\n",
    "# train and test the model\n",
    "lr.fit(X_train, y_train)\n",
    "metric = lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100.000%|██████████| 1071/1071 elapsed<00:01 remaining<00:00:01,  2.69it/s]\n",
      "Uploading: 100.000%|██████████| 714/714 elapsed<00:01 remaining<00:00<00:04,  1.07s/it]\n",
      "Model export complete: 100%|██████████| 6/6 [00:09<00:00,  1.58s/it]                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/194708/models/stockholm_incidents_model/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(name: 'stockholm_incidents_model', version: 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will now upload the linear regression model to the registry\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# The directory will be wine_model\n",
    "model_dir=\"stockholm_incidents_model\"\n",
    "if os.path.isdir(model_dir) == False:\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(lr, model_dir + \"/stckhlm_inc_model.pkl\")\n",
    "\n",
    "# Specify the input and output\n",
    "input_schema = Schema(X_train)\n",
    "output_schema = Schema(y_train)\n",
    "model_schema = ModelSchema(input_schema, output_schema)\n",
    "\n",
    "# Create an entry\n",
    "wine_model = mr.python.create_model(\n",
    "    name=\"stockholm_incidents_model\", \n",
    "    metrics={\"MSE\" : metric},\n",
    "    model_schema=model_schema,\n",
    "    description=\"Stockholm Incident duration Predictor\"\n",
    ")\n",
    "\n",
    "# Upload the model to the model registry, including all files in 'model_dir'\n",
    "wine_model.save(model_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
